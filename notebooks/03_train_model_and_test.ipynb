{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.cuda.amp import GradScaler, autocast  # For mixed precision training\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sentencepiece as spm \n",
    "import lightning as L\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from torchmetrics.classification import MulticlassF1Score\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, StochasticWeightAveraging\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/lexeme_data_with_forms_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexeme</th>\n",
       "      <th>language</th>\n",
       "      <th>pos</th>\n",
       "      <th>stem_text</th>\n",
       "      <th>contlex</th>\n",
       "      <th>forms</th>\n",
       "      <th>lexeme_and_forms</th>\n",
       "      <th>bpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>taibsted</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>taaibâst</td>\n",
       "      <td>V_MAINSTED</td>\n",
       "      <td>taaibâst taaibast taaibstem taibstem taaibsti ...</td>\n",
       "      <td>taibsted taaibstâkaz taibstâkaz</td>\n",
       "      <td>▁tai b sted ▁taa ib stâkaz ▁tai b stâkaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ääʹll</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>ää%{ʹØ%}ll</td>\n",
       "      <td>N_SAAQMM</td>\n",
       "      <td>ääʹlest älla ääʹli aaʹli ääʹll ääʹl ääʹlstes ä...</td>\n",
       "      <td>ääʹll ällsan</td>\n",
       "      <td>▁ää ʹ ll ▁ä llsan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>njââʹllvaaldõs</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>njââʹllvaaldõ%^1VOW%{ʹØ%}s</td>\n",
       "      <td>N_SAJOS</td>\n",
       "      <td>njââʹllvaaldõõzzâst njââʹllvaaldõʹsse njââʹllv...</td>\n",
       "      <td>njââʹllvaaldõs njââʹllvaaldõssʼsan</td>\n",
       "      <td>▁njââ ʹ ll vaald õs ▁njââ ʹ ll vaa ldõss ʼ san</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>läukkad</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>lä%^1VOWukk</td>\n",
       "      <td>V_LAEULLAD</td>\n",
       "      <td>lääuk läukk laukkum lääukai läukkad lääukam la...</td>\n",
       "      <td>läukkad läukkaz</td>\n",
       "      <td>▁läu kkad ▁läu kkaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>laukkõõllâd</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>laukkõõ%{ʹØ%}ll</td>\n",
       "      <td>V_LAUKKOOLLYD</td>\n",
       "      <td>laukkõõl laukkââll laukkõʹllem laukkõõli laukk...</td>\n",
       "      <td>laukkõõllâd laukkâllaz</td>\n",
       "      <td>▁lau kk õõllâd ▁lau kk âllaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24034</th>\n",
       "      <td>jieʹllidåhttar</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>jieʹlli#dåhttar</td>\n",
       "      <td>N_AANAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jieʹllidåhttar</td>\n",
       "      <td>▁jie ʹ ll id åhtt ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24035</th>\n",
       "      <td>nuõrrǥaž</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>nuõrrǥ</td>\n",
       "      <td>N_MEERSAZH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nuõrrǥaž</td>\n",
       "      <td>▁nuõ rr ǥ až</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24036</th>\n",
       "      <td>looǥǥâlm</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>looǥǥâlm</td>\n",
       "      <td>N_COOGGYLM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>looǥǥâlm</td>\n",
       "      <td>▁looǥǥ âlm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24037</th>\n",
       "      <td>paneelsaǥstõõllmõš</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>panẹẹl#saǥ»stõõll»mõ%^1VOW%{ʹØ%}š</td>\n",
       "      <td>N_SAJOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>paneelsaǥstõõllmõš</td>\n",
       "      <td>▁pan ee l sa ǥ stõõllmõš</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24038</th>\n",
       "      <td>pueʹreemeʹtǩǩõs</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>pueʹreem#eʹtǩǩõ%^1VOW%{ʹØ%}s</td>\n",
       "      <td>N_SAJOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pueʹreemeʹtǩǩõs</td>\n",
       "      <td>▁pue ʹ r eem e ʹ tǩǩ õs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24039 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   lexeme language pos                          stem_text  \\\n",
       "0                taibsted      sms   V                           taaibâst   \n",
       "1                   ääʹll      sms   N                         ää%{ʹØ%}ll   \n",
       "2          njââʹllvaaldõs      sms   N         njââʹllvaaldõ%^1VOW%{ʹØ%}s   \n",
       "3                 läukkad      sms   V                        lä%^1VOWukk   \n",
       "4             laukkõõllâd      sms   V                    laukkõõ%{ʹØ%}ll   \n",
       "...                   ...      ...  ..                                ...   \n",
       "24034      jieʹllidåhttar      sms   N                    jieʹlli#dåhttar   \n",
       "24035            nuõrrǥaž      sms   N                             nuõrrǥ   \n",
       "24036            looǥǥâlm      sms   N                           looǥǥâlm   \n",
       "24037  paneelsaǥstõõllmõš      sms   N  panẹẹl#saǥ»stõõll»mõ%^1VOW%{ʹØ%}š   \n",
       "24038     pueʹreemeʹtǩǩõs      sms   N       pueʹreem#eʹtǩǩõ%^1VOW%{ʹØ%}s   \n",
       "\n",
       "             contlex                                              forms  \\\n",
       "0         V_MAINSTED  taaibâst taaibast taaibstem taibstem taaibsti ...   \n",
       "1           N_SAAQMM  ääʹlest älla ääʹli aaʹli ääʹll ääʹl ääʹlstes ä...   \n",
       "2            N_SAJOS  njââʹllvaaldõõzzâst njââʹllvaaldõʹsse njââʹllv...   \n",
       "3         V_LAEULLAD  lääuk läukk laukkum lääukai läukkad lääukam la...   \n",
       "4      V_LAUKKOOLLYD  laukkõõl laukkââll laukkõʹllem laukkõõli laukk...   \n",
       "...              ...                                                ...   \n",
       "24034        N_AANAR                                                NaN   \n",
       "24035     N_MEERSAZH                                                NaN   \n",
       "24036     N_COOGGYLM                                                NaN   \n",
       "24037        N_SAJOS                                                NaN   \n",
       "24038        N_SAJOS                                                NaN   \n",
       "\n",
       "                         lexeme_and_forms  \\\n",
       "0         taibsted taaibstâkaz taibstâkaz   \n",
       "1                            ääʹll ällsan   \n",
       "2      njââʹllvaaldõs njââʹllvaaldõssʼsan   \n",
       "3                         läukkad läukkaz   \n",
       "4                  laukkõõllâd laukkâllaz   \n",
       "...                                   ...   \n",
       "24034                     jieʹllidåhttar    \n",
       "24035                           nuõrrǥaž    \n",
       "24036                           looǥǥâlm    \n",
       "24037                 paneelsaǥstõõllmõš    \n",
       "24038                    pueʹreemeʹtǩǩõs    \n",
       "\n",
       "                                                  bpe  \n",
       "0            ▁tai b sted ▁taa ib stâkaz ▁tai b stâkaz  \n",
       "1                                   ▁ää ʹ ll ▁ä llsan  \n",
       "2      ▁njââ ʹ ll vaald õs ▁njââ ʹ ll vaa ldõss ʼ san  \n",
       "3                                 ▁läu kkad ▁läu kkaz  \n",
       "4                        ▁lau kk õõllâd ▁lau kk âllaz  \n",
       "...                                               ...  \n",
       "24034                            ▁jie ʹ ll id åhtt ar  \n",
       "24035                                    ▁nuõ rr ǥ až  \n",
       "24036                                      ▁looǥǥ âlm  \n",
       "24037                        ▁pan ee l sa ǥ stõõllmõš  \n",
       "24038                         ▁pue ʹ r eem e ʹ tǩǩ õs  \n",
       "\n",
       "[24039 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = data.copy()\n",
    "clean_data.dropna(subset=[\"forms\"], inplace=True)\n",
    "clean_data.drop(columns=[\"lexeme_and_forms\", \"bpe\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexeme</th>\n",
       "      <th>language</th>\n",
       "      <th>pos</th>\n",
       "      <th>stem_text</th>\n",
       "      <th>contlex</th>\n",
       "      <th>forms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>taibsted</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>taaibâst</td>\n",
       "      <td>V_MAINSTED</td>\n",
       "      <td>taaibâst taaibast taaibstem taibstem taaibsti ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ääʹll</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>ää%{ʹØ%}ll</td>\n",
       "      <td>N_SAAQMM</td>\n",
       "      <td>ääʹlest älla ääʹli aaʹli ääʹll ääʹl ääʹlstes ä...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>njââʹllvaaldõs</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>njââʹllvaaldõ%^1VOW%{ʹØ%}s</td>\n",
       "      <td>N_SAJOS</td>\n",
       "      <td>njââʹllvaaldõõzzâst njââʹllvaaldõʹsse njââʹllv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>läukkad</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>lä%^1VOWukk</td>\n",
       "      <td>V_LAEULLAD</td>\n",
       "      <td>lääuk läukk laukkum lääukai läukkad lääukam la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>laukkõõllâd</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>laukkõõ%{ʹØ%}ll</td>\n",
       "      <td>V_LAUKKOOLLYD</td>\n",
       "      <td>laukkõõl laukkââll laukkõʹllem laukkõõli laukk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24027</th>\n",
       "      <td>riikkvääraiministeria</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>riikk#väärai#ministeria</td>\n",
       "      <td>N_BIOLOGIA</td>\n",
       "      <td>riikkvääraiministeriast riikkvääraiministeriaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24028</th>\n",
       "      <td>nõõmuʹvddem-moʹlidva</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>nõõm#uʹvddem-#moʹlidva</td>\n",
       "      <td>N_BUKVA</td>\n",
       "      <td>nõõmuʹvddem-moʹlidvast nõõmuʹvddem-moʹlidvaaʹj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24029</th>\n",
       "      <td>teevvamhåidd</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>teevvam#hå%^1VOWidd</td>\n",
       "      <td>N_AELDD</td>\n",
       "      <td>teevvamhååidast teevvamhoiddu teevvamhååidai t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24030</th>\n",
       "      <td>koomačkåhtt</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>koomač#kå%^1VOWhtt</td>\n",
       "      <td>N_KOAHTT</td>\n",
       "      <td>koomačkååutast koomačkohttu koomačkååutai koom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24032</th>\n",
       "      <td>maaʹlʼjed</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>maaʹl</td>\n",
       "      <td>TV_VOQLLJED</td>\n",
       "      <td>maaʹle maaʹlai maaʹlʼjem maaʹlʼji maaʹlʼjed ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22418 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      lexeme language pos                   stem_text  \\\n",
       "0                   taibsted      sms   V                    taaibâst   \n",
       "1                      ääʹll      sms   N                  ää%{ʹØ%}ll   \n",
       "2             njââʹllvaaldõs      sms   N  njââʹllvaaldõ%^1VOW%{ʹØ%}s   \n",
       "3                    läukkad      sms   V                 lä%^1VOWukk   \n",
       "4                laukkõõllâd      sms   V             laukkõõ%{ʹØ%}ll   \n",
       "...                      ...      ...  ..                         ...   \n",
       "24027  riikkvääraiministeria      sms   N     riikk#väärai#ministeria   \n",
       "24028   nõõmuʹvddem-moʹlidva      sms   N      nõõm#uʹvddem-#moʹlidva   \n",
       "24029           teevvamhåidd      sms   N         teevvam#hå%^1VOWidd   \n",
       "24030            koomačkåhtt      sms   N          koomač#kå%^1VOWhtt   \n",
       "24032              maaʹlʼjed      sms   V                       maaʹl   \n",
       "\n",
       "             contlex                                              forms  \n",
       "0         V_MAINSTED  taaibâst taaibast taaibstem taibstem taaibsti ...  \n",
       "1           N_SAAQMM  ääʹlest älla ääʹli aaʹli ääʹll ääʹl ääʹlstes ä...  \n",
       "2            N_SAJOS  njââʹllvaaldõõzzâst njââʹllvaaldõʹsse njââʹllv...  \n",
       "3         V_LAEULLAD  lääuk läukk laukkum lääukai läukkad lääukam la...  \n",
       "4      V_LAUKKOOLLYD  laukkõõl laukkââll laukkõʹllem laukkõõli laukk...  \n",
       "...              ...                                                ...  \n",
       "24027     N_BIOLOGIA  riikkvääraiministeriast riikkvääraiministeriaa...  \n",
       "24028        N_BUKVA  nõõmuʹvddem-moʹlidvast nõõmuʹvddem-moʹlidvaaʹj...  \n",
       "24029        N_AELDD  teevvamhååidast teevvamhoiddu teevvamhååidai t...  \n",
       "24030       N_KOAHTT  koomačkååutast koomačkohttu koomačkååutai koom...  \n",
       "24032    TV_VOQLLJED  maaʹle maaʹlai maaʹlʼjem maaʹlʼji maaʹlʼjed ma...  \n",
       "\n",
       "[22418 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "939"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_data[\"contlex\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data[\"label\"] = clean_data[\"contlex\"].str.split('_').str[:2].str.join('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexeme</th>\n",
       "      <th>language</th>\n",
       "      <th>pos</th>\n",
       "      <th>stem_text</th>\n",
       "      <th>contlex</th>\n",
       "      <th>forms</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>taibsted</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>taaibâst</td>\n",
       "      <td>V_MAINSTED</td>\n",
       "      <td>taaibâst taaibast taaibstem taibstem taaibsti ...</td>\n",
       "      <td>V_MAINSTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ääʹll</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>ää%{ʹØ%}ll</td>\n",
       "      <td>N_SAAQMM</td>\n",
       "      <td>ääʹlest älla ääʹli aaʹli ääʹll ääʹl ääʹlstes ä...</td>\n",
       "      <td>N_SAAQMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>njââʹllvaaldõs</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>njââʹllvaaldõ%^1VOW%{ʹØ%}s</td>\n",
       "      <td>N_SAJOS</td>\n",
       "      <td>njââʹllvaaldõõzzâst njââʹllvaaldõʹsse njââʹllv...</td>\n",
       "      <td>N_SAJOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>läukkad</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>lä%^1VOWukk</td>\n",
       "      <td>V_LAEULLAD</td>\n",
       "      <td>lääuk läukk laukkum lääukai läukkad lääukam la...</td>\n",
       "      <td>V_LAEULLAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>laukkõõllâd</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>laukkõõ%{ʹØ%}ll</td>\n",
       "      <td>V_LAUKKOOLLYD</td>\n",
       "      <td>laukkõõl laukkââll laukkõʹllem laukkõõli laukk...</td>\n",
       "      <td>V_LAUKKOOLLYD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24027</th>\n",
       "      <td>riikkvääraiministeria</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>riikk#väärai#ministeria</td>\n",
       "      <td>N_BIOLOGIA</td>\n",
       "      <td>riikkvääraiministeriast riikkvääraiministeriaa...</td>\n",
       "      <td>N_BIOLOGIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24028</th>\n",
       "      <td>nõõmuʹvddem-moʹlidva</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>nõõm#uʹvddem-#moʹlidva</td>\n",
       "      <td>N_BUKVA</td>\n",
       "      <td>nõõmuʹvddem-moʹlidvast nõõmuʹvddem-moʹlidvaaʹj...</td>\n",
       "      <td>N_BUKVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24029</th>\n",
       "      <td>teevvamhåidd</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>teevvam#hå%^1VOWidd</td>\n",
       "      <td>N_AELDD</td>\n",
       "      <td>teevvamhååidast teevvamhoiddu teevvamhååidai t...</td>\n",
       "      <td>N_AELDD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24030</th>\n",
       "      <td>koomačkåhtt</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>koomač#kå%^1VOWhtt</td>\n",
       "      <td>N_KOAHTT</td>\n",
       "      <td>koomačkååutast koomačkohttu koomačkååutai koom...</td>\n",
       "      <td>N_KOAHTT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24032</th>\n",
       "      <td>maaʹlʼjed</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>maaʹl</td>\n",
       "      <td>TV_VOQLLJED</td>\n",
       "      <td>maaʹle maaʹlai maaʹlʼjem maaʹlʼji maaʹlʼjed ma...</td>\n",
       "      <td>TV_VOQLLJED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22418 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      lexeme language pos                   stem_text  \\\n",
       "0                   taibsted      sms   V                    taaibâst   \n",
       "1                      ääʹll      sms   N                  ää%{ʹØ%}ll   \n",
       "2             njââʹllvaaldõs      sms   N  njââʹllvaaldõ%^1VOW%{ʹØ%}s   \n",
       "3                    läukkad      sms   V                 lä%^1VOWukk   \n",
       "4                laukkõõllâd      sms   V             laukkõõ%{ʹØ%}ll   \n",
       "...                      ...      ...  ..                         ...   \n",
       "24027  riikkvääraiministeria      sms   N     riikk#väärai#ministeria   \n",
       "24028   nõõmuʹvddem-moʹlidva      sms   N      nõõm#uʹvddem-#moʹlidva   \n",
       "24029           teevvamhåidd      sms   N         teevvam#hå%^1VOWidd   \n",
       "24030            koomačkåhtt      sms   N          koomač#kå%^1VOWhtt   \n",
       "24032              maaʹlʼjed      sms   V                       maaʹl   \n",
       "\n",
       "             contlex                                              forms  \\\n",
       "0         V_MAINSTED  taaibâst taaibast taaibstem taibstem taaibsti ...   \n",
       "1           N_SAAQMM  ääʹlest älla ääʹli aaʹli ääʹll ääʹl ääʹlstes ä...   \n",
       "2            N_SAJOS  njââʹllvaaldõõzzâst njââʹllvaaldõʹsse njââʹllv...   \n",
       "3         V_LAEULLAD  lääuk läukk laukkum lääukai läukkad lääukam la...   \n",
       "4      V_LAUKKOOLLYD  laukkõõl laukkââll laukkõʹllem laukkõõli laukk...   \n",
       "...              ...                                                ...   \n",
       "24027     N_BIOLOGIA  riikkvääraiministeriast riikkvääraiministeriaa...   \n",
       "24028        N_BUKVA  nõõmuʹvddem-moʹlidvast nõõmuʹvddem-moʹlidvaaʹj...   \n",
       "24029        N_AELDD  teevvamhååidast teevvamhoiddu teevvamhååidai t...   \n",
       "24030       N_KOAHTT  koomačkååutast koomačkohttu koomačkååutai koom...   \n",
       "24032    TV_VOQLLJED  maaʹle maaʹlai maaʹlʼjem maaʹlʼji maaʹlʼjed ma...   \n",
       "\n",
       "               label  \n",
       "0         V_MAINSTED  \n",
       "1           N_SAAQMM  \n",
       "2            N_SAJOS  \n",
       "3         V_LAEULLAD  \n",
       "4      V_LAUKKOOLLYD  \n",
       "...              ...  \n",
       "24027     N_BIOLOGIA  \n",
       "24028        N_BUKVA  \n",
       "24029        N_AELDD  \n",
       "24030       N_KOAHTT  \n",
       "24032    TV_VOQLLJED  \n",
       "\n",
       "[22418 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "N_SAJOS           5969\n",
       "N_MAINSTUMMUSH    1557\n",
       "N_MUORR            792\n",
       "N_AANAR            616\n",
       "V_LAUKKOOLLYD      609\n",
       "                  ... \n",
       "N_CHEE               1\n",
       "IV_TEYPSTED          1\n",
       "IV_LEEQD             1\n",
       "N_PUUQTTES           1\n",
       "N_KARIES             1\n",
       "Name: count, Length: 514, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_counts = clean_data[\"label\"].value_counts()\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count\n",
       "1      104\n",
       "2       57\n",
       "3       35\n",
       "5       32\n",
       "4       31\n",
       "      ... \n",
       "136      1\n",
       "144      1\n",
       "149      1\n",
       "151      1\n",
       "63       1\n",
       "Name: count, Length: 103, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_of_counts = label_counts.value_counts()\n",
    "counts_of_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rare_combinations(data, contlex_column='contlex', min_samples=20):\n",
    "    label_counts = data[contlex_column].value_counts()\n",
    "    \n",
    "    frequent_labels = label_counts[label_counts >= min_samples].index\n",
    "\n",
    "    filtered_data = data[data[contlex_column].isin(frequent_labels)]\n",
    "    \n",
    "    return filtered_data.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexeme</th>\n",
       "      <th>language</th>\n",
       "      <th>pos</th>\n",
       "      <th>stem_text</th>\n",
       "      <th>contlex</th>\n",
       "      <th>forms</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ääʹll</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>ää%{ʹØ%}ll</td>\n",
       "      <td>N_SAAQMM</td>\n",
       "      <td>ääʹlest älla ääʹli aaʹli ääʹll ääʹl ääʹlstes ä...</td>\n",
       "      <td>N_SAAQMM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>njââʹllvaaldõs</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>njââʹllvaaldõ%^1VOW%{ʹØ%}s</td>\n",
       "      <td>N_SAJOS</td>\n",
       "      <td>njââʹllvaaldõõzzâst njââʹllvaaldõʹsse njââʹllv...</td>\n",
       "      <td>N_SAJOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>laukkõõllâd</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>laukkõõ%{ʹØ%}ll</td>\n",
       "      <td>V_LAUKKOOLLYD</td>\n",
       "      <td>laukkõõl laukkââll laukkõʹllem laukkõõli laukk...</td>\n",
       "      <td>V_LAUKKOOLLYD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hiâvtõõttâd</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>hiâvtõõ%{ʹØ%}tt</td>\n",
       "      <td>V_LAUKKOOLLYD</td>\n",
       "      <td>hiâvtõõđ hiâvtââtt hiâvtõʹttem hiâvtõõđi hiâvt...</td>\n",
       "      <td>V_LAUKKOOLLYD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hiâvtõõttâd</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>hiõvtõõ%{ʹØ%}tt</td>\n",
       "      <td>V_LAUKKOOLLYD_ERRORTH</td>\n",
       "      <td>hiâvtõõđ hiâvtââtt hiâvtõʹttem hiâvtõõđi hiâvt...</td>\n",
       "      <td>V_LAUKKOOLLYD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18572</th>\n",
       "      <td>puåtkknõddâd</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>puåtkknõ%^1VOW%{ʹØ%}dd</td>\n",
       "      <td>V_ROVVYD</td>\n",
       "      <td>puåtkknõõdd puåtkknâdd puåtkknõʹddem puåtkknõõ...</td>\n",
       "      <td>V_ROVVYD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18573</th>\n",
       "      <td>ruõššlaž</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>ruõšˈšl</td>\n",
       "      <td>N_MEERSAZH_SEMHUM</td>\n",
       "      <td>ruõššlast ruõššlõʹžže ruõššlai ruõššlaž ruõššl...</td>\n",
       "      <td>N_MEERSAZH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18574</th>\n",
       "      <td>riikkvääraiministeria</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>riikk#väärai#ministeria</td>\n",
       "      <td>N_BIOLOGIA</td>\n",
       "      <td>riikkvääraiministeriast riikkvääraiministeriaa...</td>\n",
       "      <td>N_BIOLOGIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18575</th>\n",
       "      <td>teevvamhåidd</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>teevvam#hå%^1VOWidd</td>\n",
       "      <td>N_AELDD</td>\n",
       "      <td>teevvamhååidast teevvamhoiddu teevvamhååidai t...</td>\n",
       "      <td>N_AELDD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18576</th>\n",
       "      <td>maaʹlʼjed</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>maaʹl</td>\n",
       "      <td>TV_VOQLLJED</td>\n",
       "      <td>maaʹle maaʹlai maaʹlʼjem maaʹlʼji maaʹlʼjed ma...</td>\n",
       "      <td>TV_VOQLLJED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18577 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      lexeme language pos                   stem_text  \\\n",
       "0                      ääʹll      sms   N                  ää%{ʹØ%}ll   \n",
       "1             njââʹllvaaldõs      sms   N  njââʹllvaaldõ%^1VOW%{ʹØ%}s   \n",
       "2                laukkõõllâd      sms   V             laukkõõ%{ʹØ%}ll   \n",
       "3                hiâvtõõttâd      sms   V             hiâvtõõ%{ʹØ%}tt   \n",
       "4                hiâvtõõttâd      sms   V             hiõvtõõ%{ʹØ%}tt   \n",
       "...                      ...      ...  ..                         ...   \n",
       "18572           puåtkknõddâd      sms   V      puåtkknõ%^1VOW%{ʹØ%}dd   \n",
       "18573               ruõššlaž      sms   N                     ruõšˈšl   \n",
       "18574  riikkvääraiministeria      sms   N     riikk#väärai#ministeria   \n",
       "18575           teevvamhåidd      sms   N         teevvam#hå%^1VOWidd   \n",
       "18576              maaʹlʼjed      sms   V                       maaʹl   \n",
       "\n",
       "                     contlex  \\\n",
       "0                   N_SAAQMM   \n",
       "1                    N_SAJOS   \n",
       "2              V_LAUKKOOLLYD   \n",
       "3              V_LAUKKOOLLYD   \n",
       "4      V_LAUKKOOLLYD_ERRORTH   \n",
       "...                      ...   \n",
       "18572               V_ROVVYD   \n",
       "18573      N_MEERSAZH_SEMHUM   \n",
       "18574             N_BIOLOGIA   \n",
       "18575                N_AELDD   \n",
       "18576            TV_VOQLLJED   \n",
       "\n",
       "                                                   forms          label  \n",
       "0      ääʹlest älla ääʹli aaʹli ääʹll ääʹl ääʹlstes ä...       N_SAAQMM  \n",
       "1      njââʹllvaaldõõzzâst njââʹllvaaldõʹsse njââʹllv...        N_SAJOS  \n",
       "2      laukkõõl laukkââll laukkõʹllem laukkõõli laukk...  V_LAUKKOOLLYD  \n",
       "3      hiâvtõõđ hiâvtââtt hiâvtõʹttem hiâvtõõđi hiâvt...  V_LAUKKOOLLYD  \n",
       "4      hiâvtõõđ hiâvtââtt hiâvtõʹttem hiâvtõõđi hiâvt...  V_LAUKKOOLLYD  \n",
       "...                                                  ...            ...  \n",
       "18572  puåtkknõõdd puåtkknâdd puåtkknõʹddem puåtkknõõ...       V_ROVVYD  \n",
       "18573  ruõššlast ruõššlõʹžže ruõššlai ruõššlaž ruõššl...     N_MEERSAZH  \n",
       "18574  riikkvääraiministeriast riikkvääraiministeriaa...     N_BIOLOGIA  \n",
       "18575  teevvamhååidast teevvamhoiddu teevvamhååidai t...        N_AELDD  \n",
       "18576  maaʹle maaʹlai maaʹlʼjem maaʹlʼji maaʹlʼjed ma...    TV_VOQLLJED  \n",
       "\n",
       "[18577 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = remove_rare_combinations(clean_data, contlex_column='label', min_samples=50)\n",
    "\n",
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "N_SAJOS           5969\n",
       "N_MAINSTUMMUSH    1557\n",
       "N_MUORR            792\n",
       "N_AANAR            616\n",
       "V_LAUKKOOLLYD      609\n",
       "                  ... \n",
       "V_ROVVYD            54\n",
       "N_TAQHTT            52\n",
       "N_KHEQRJJ           52\n",
       "V_JEAELSTED         52\n",
       "N_SIYKKK            52\n",
       "Name: count, Length: 73, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_data[\"label\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N': 52, 'V': 21}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.groupby(\"pos\")[\"label\"].nunique().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor(model_file='./skolt_bpe_3.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelEncoderManager:\n",
    "    def __init__(self):\n",
    "        self.pos_encoder = LabelEncoder()\n",
    "        self.contlex_encoders = {}  # Dictionary to hold a LabelEncoder for each POS class\n",
    "\n",
    "    def fit(self, pos_labels, contlex_labels):\n",
    "        \"\"\"\n",
    "        Fit the POS encoder and the contlex encoders based on the corresponding POS.\n",
    "        \n",
    "        pos_labels: List or array of POS labels.\n",
    "        contlex_labels: List or array of contlex labels.\n",
    "        \"\"\"\n",
    "        # Fit the POS encoder\n",
    "        self.pos_encoder.fit(pos_labels)\n",
    "\n",
    "        # Initialize and fit a LabelEncoder for each unique POS class\n",
    "        unique_pos = set(pos_labels)\n",
    "        for pos_class in unique_pos:\n",
    "            contlex_for_pos = [contlex_labels[i] for i in range(len(pos_labels)) if pos_labels[i] == pos_class]\n",
    "            encoder = LabelEncoder()\n",
    "            encoder.fit(contlex_for_pos)\n",
    "            self.contlex_encoders[pos_class] = encoder\n",
    "\n",
    "    def transform_pos(self, pos_labels):\n",
    "        \"\"\"Transform POS labels using the POS encoder.\"\"\"\n",
    "        return self.pos_encoder.transform(pos_labels)\n",
    "\n",
    "    def inverse_transform_pos(self, encoded_pos_labels):\n",
    "        \"\"\"Inverse transform encoded POS labels using the POS encoder.\"\"\"\n",
    "        return self.pos_encoder.inverse_transform(encoded_pos_labels)\n",
    "\n",
    "    def transform_contlex(self, pos_labels, contlex_labels):\n",
    "        \"\"\"\n",
    "        Transform contlex labels using the corresponding encoder for each POS class.\n",
    "        \n",
    "        pos_labels: List or array of POS labels (used to select the corresponding contlex encoder).\n",
    "        contlex_labels: List or array of contlex labels to be encoded.\n",
    "        \"\"\"\n",
    "        encoded_contlex_labels = []\n",
    "        for pos, contlex in zip(pos_labels, contlex_labels):\n",
    "            encoder = self.contlex_encoders.get(pos)\n",
    "            if encoder is not None:\n",
    "                encoded_contlex_labels.append(encoder.transform([contlex])[0])\n",
    "            else:\n",
    "                raise ValueError(f\"No contlex encoder found for POS class: {pos}\")\n",
    "        return encoded_contlex_labels\n",
    "\n",
    "    def inverse_transform_contlex(self, pos_labels, encoded_contlex_labels):\n",
    "        \"\"\"\n",
    "        Inverse transform contlex labels using the corresponding encoder for each POS class.\n",
    "        \n",
    "        pos_labels: List or array of POS labels (used to select the corresponding contlex encoder).\n",
    "        encoded_contlex_labels: List or array of encoded contlex labels to be inverse transformed.\n",
    "        \"\"\"\n",
    "        contlex_labels = []\n",
    "        for pos, enc_contlex in zip(pos_labels, encoded_contlex_labels):\n",
    "            encoder = self.contlex_encoders.get(pos)\n",
    "            if encoder is not None:\n",
    "                contlex_labels.append(encoder.inverse_transform([enc_contlex])[0])\n",
    "            else:\n",
    "                raise ValueError(f\"No contlex encoder found for POS class: {pos}\")\n",
    "        return contlex_labels\n",
    "\n",
    "    def save_encoders(self, path):\n",
    "        \"\"\"\n",
    "        Save the POS encoder and contlex encoders to a file using pickle.\n",
    "        \n",
    "        path: The file path where the encoders will be saved.\n",
    "        \"\"\"\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump({'pos_encoder': self.pos_encoder, 'contlex_encoders': self.contlex_encoders}, f)\n",
    "\n",
    "    def load_encoders(self, path):\n",
    "        \"\"\"\n",
    "        Load the POS encoder and contlex encoders from a file using pickle.\n",
    "        \n",
    "        path: The file path where the encoders are stored.\n",
    "        \"\"\"\n",
    "        with open(path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            self.pos_encoder = data['pos_encoder']\n",
    "            self.contlex_encoders = data['contlex_encoders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, pos_labels, contlex_labels):\n",
    "        self.X = X\n",
    "        self.pos_labels = pos_labels\n",
    "        self.contlex_labels = contlex_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X_item = torch.tensor(self.X[idx], dtype=torch.long)\n",
    "        pos_label = torch.tensor(self.pos_labels[idx], dtype=torch.long)\n",
    "        contlex_label = torch.tensor(self.contlex_labels[idx], dtype=torch.long)\n",
    "        return X_item, pos_label, contlex_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data[\"X\"] = clean_data[\"lexeme\"] + \" \" + clean_data[\"forms\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data = train_test_split(clean_data, test_size=0.1, random_state=42, stratify=clean_data[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexeme</th>\n",
       "      <th>language</th>\n",
       "      <th>pos</th>\n",
       "      <th>stem_text</th>\n",
       "      <th>contlex</th>\n",
       "      <th>forms</th>\n",
       "      <th>label</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6909</th>\n",
       "      <td>põõrǥâståimm</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>põõrǥâs#tå%^1VOWimm</td>\n",
       "      <td>N_AELDD</td>\n",
       "      <td>põõrǥâstååimast põõrǥâstoimmu põõrǥâstååimai p...</td>\n",
       "      <td>N_AELDD</td>\n",
       "      <td>põõrǥâståimm põõrǥâstååimast põõrǥâstoimmu põõ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7341</th>\n",
       "      <td>ǩeʹrjjvacc</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>ǩeʹrjj#va%^1VOW%{ʹØ%}cc</td>\n",
       "      <td>N_PAPP</td>\n",
       "      <td>ǩeʹrjjvaaccâst ǩeʹrjjvaʹcce ǩeʹrjjvaacci ǩeʹrj...</td>\n",
       "      <td>N_PAPP</td>\n",
       "      <td>ǩeʹrjjvacc ǩeʹrjjvaaccâst ǩeʹrjjvaʹcce ǩeʹrjjv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8005</th>\n",
       "      <td>tieʹddtummuš</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>tieʹddtummuš</td>\n",
       "      <td>N_MAINSTUMMUSH</td>\n",
       "      <td>tieʹddtummšest tieʹddtummša tieʹddtummši tieʹd...</td>\n",
       "      <td>N_MAINSTUMMUSH</td>\n",
       "      <td>tieʹddtummuš tieʹddtummšest tieʹddtummša tieʹd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>vuõjjšõõddmõš</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>vuõjjšõõdd»mõ%^1VOW%{ʹØ%}š</td>\n",
       "      <td>N_SAJOS</td>\n",
       "      <td>vuõjjšõõddmuužžâst vuõjjšõõddmõõžžâst vuõjjšõõ...</td>\n",
       "      <td>N_SAJOS</td>\n",
       "      <td>vuõjjšõõddmõš vuõjjšõõddmuužžâst vuõjjšõõddmõõ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9847</th>\n",
       "      <td>sǩiâŋkk</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>#sǩiâ%{ʹØ%}ŋkk</td>\n",
       "      <td>N_MIYRKK</td>\n",
       "      <td>sǩiâŋkâst sǩieʹŋǩǩe sǩiâŋki sǩiâŋkk sǩiâŋk sǩi...</td>\n",
       "      <td>N_MIYRKK</td>\n",
       "      <td>sǩiâŋkk sǩiâŋkâst sǩieʹŋǩǩe sǩiâŋki sǩiâŋkk sǩ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13105</th>\n",
       "      <td>vuõleed</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>vuõl</td>\n",
       "      <td>V_SILTTEED</td>\n",
       "      <td>vuõlâd vuõlad vuõleem vuõlii vuõleed vuõlääm v...</td>\n",
       "      <td>V_SILTTEED</td>\n",
       "      <td>vuõleed vuõlâd vuõlad vuõleem vuõlii vuõleed v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4110</th>\n",
       "      <td>sieʹǩǩporrmõš</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>sieʹǩǩporr»mõ%^1VOW%{ʹØ%}š</td>\n",
       "      <td>N_SAJOS</td>\n",
       "      <td>sieʹǩǩporrmuužžâst sieʹǩǩporrmõõžžâst sieʹǩǩpo...</td>\n",
       "      <td>N_SAJOS</td>\n",
       "      <td>sieʹǩǩporrmõš sieʹǩǩporrmuužžâst sieʹǩǩporrmõõ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>čårrmeäʹcc</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>čårr#meä%{ʹØ%}cˈc</td>\n",
       "      <td>N_JEAQNNN</td>\n",
       "      <td>čårrmieʹccest čårrmeäcca čårrmieʹcci čårrmeäʹc...</td>\n",
       "      <td>N_JEAQNNN</td>\n",
       "      <td>čårrmeäʹcc čårrmieʹccest čårrmeäcca čårrmieʹcc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15078</th>\n",
       "      <td>jiâkstõõttâd</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>jiâˈkstõõ%{ʹØ%}tt</td>\n",
       "      <td>V_LAUKKOOLLYD</td>\n",
       "      <td>jiâkstõõđ jiâkstââtt jiâkstõʹttem jiâkstõõđi j...</td>\n",
       "      <td>V_LAUKKOOLLYD</td>\n",
       "      <td>jiâkstõõttâd jiâkstõõđ jiâkstââtt jiâkstõʹttem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4382</th>\n",
       "      <td>suâinnõõvvâd</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>suâinnõõ%{ʹØ%}vv</td>\n",
       "      <td>V_LAUKKOOLLYD</td>\n",
       "      <td>suâinnõõv suâinnââvv suâinnõʹvvem suâinnõõvi s...</td>\n",
       "      <td>V_LAUKKOOLLYD</td>\n",
       "      <td>suâinnõõvvâd suâinnõõv suâinnââvv suâinnõʹvvem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16719 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              lexeme language pos                   stem_text         contlex  \\\n",
       "6909    põõrǥâståimm      sms   N         põõrǥâs#tå%^1VOWimm         N_AELDD   \n",
       "7341      ǩeʹrjjvacc      sms   N     ǩeʹrjj#va%^1VOW%{ʹØ%}cc          N_PAPP   \n",
       "8005    tieʹddtummuš      sms   N                tieʹddtummuš  N_MAINSTUMMUSH   \n",
       "1155   vuõjjšõõddmõš      sms   N  vuõjjšõõdd»mõ%^1VOW%{ʹØ%}š         N_SAJOS   \n",
       "9847         sǩiâŋkk      sms   N              #sǩiâ%{ʹØ%}ŋkk        N_MIYRKK   \n",
       "...              ...      ...  ..                         ...             ...   \n",
       "13105        vuõleed      sms   V                        vuõl      V_SILTTEED   \n",
       "4110   sieʹǩǩporrmõš      sms   N  sieʹǩǩporr»mõ%^1VOW%{ʹØ%}š         N_SAJOS   \n",
       "2677      čårrmeäʹcc      sms   N           čårr#meä%{ʹØ%}cˈc       N_JEAQNNN   \n",
       "15078   jiâkstõõttâd      sms   V           jiâˈkstõõ%{ʹØ%}tt   V_LAUKKOOLLYD   \n",
       "4382    suâinnõõvvâd      sms   V            suâinnõõ%{ʹØ%}vv   V_LAUKKOOLLYD   \n",
       "\n",
       "                                                   forms           label  \\\n",
       "6909   põõrǥâstååimast põõrǥâstoimmu põõrǥâstååimai p...         N_AELDD   \n",
       "7341   ǩeʹrjjvaaccâst ǩeʹrjjvaʹcce ǩeʹrjjvaacci ǩeʹrj...          N_PAPP   \n",
       "8005   tieʹddtummšest tieʹddtummša tieʹddtummši tieʹd...  N_MAINSTUMMUSH   \n",
       "1155   vuõjjšõõddmuužžâst vuõjjšõõddmõõžžâst vuõjjšõõ...         N_SAJOS   \n",
       "9847   sǩiâŋkâst sǩieʹŋǩǩe sǩiâŋki sǩiâŋkk sǩiâŋk sǩi...        N_MIYRKK   \n",
       "...                                                  ...             ...   \n",
       "13105  vuõlâd vuõlad vuõleem vuõlii vuõleed vuõlääm v...      V_SILTTEED   \n",
       "4110   sieʹǩǩporrmuužžâst sieʹǩǩporrmõõžžâst sieʹǩǩpo...         N_SAJOS   \n",
       "2677   čårrmieʹccest čårrmeäcca čårrmieʹcci čårrmeäʹc...       N_JEAQNNN   \n",
       "15078  jiâkstõõđ jiâkstââtt jiâkstõʹttem jiâkstõõđi j...   V_LAUKKOOLLYD   \n",
       "4382   suâinnõõv suâinnââvv suâinnõʹvvem suâinnõõvi s...   V_LAUKKOOLLYD   \n",
       "\n",
       "                                                       X  \n",
       "6909   põõrǥâståimm põõrǥâstååimast põõrǥâstoimmu põõ...  \n",
       "7341   ǩeʹrjjvacc ǩeʹrjjvaaccâst ǩeʹrjjvaʹcce ǩeʹrjjv...  \n",
       "8005   tieʹddtummuš tieʹddtummšest tieʹddtummša tieʹd...  \n",
       "1155   vuõjjšõõddmõš vuõjjšõõddmuužžâst vuõjjšõõddmõõ...  \n",
       "9847   sǩiâŋkk sǩiâŋkâst sǩieʹŋǩǩe sǩiâŋki sǩiâŋkk sǩ...  \n",
       "...                                                  ...  \n",
       "13105  vuõleed vuõlâd vuõlad vuõleem vuõlii vuõleed v...  \n",
       "4110   sieʹǩǩporrmõš sieʹǩǩporrmuužžâst sieʹǩǩporrmõõ...  \n",
       "2677   čårrmeäʹcc čårrmieʹccest čårrmeäcca čårrmieʹcc...  \n",
       "15078  jiâkstõõttâd jiâkstõõđ jiâkstââtt jiâkstõʹttem...  \n",
       "4382   suâinnõõvvâd suâinnõõv suâinnââvv suâinnõʹvvem...  \n",
       "\n",
       "[16719 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_input(texts, sp_model):\n",
    "    \"\"\"\n",
    "    Tokenize input text using a SentencePiece model.\n",
    "    \n",
    "    texts: List of input texts to be tokenized.\n",
    "    sp_model: SentencePiece model to tokenize the texts.\n",
    "    \n",
    "    Returns:\n",
    "    tokenized_texts: List of tokenized and padded input sequences.\n",
    "    max_len: Maximum sequence length.\n",
    "    vocab_size: Size of the vocabulary.\n",
    "    \"\"\"\n",
    "    tokenized_texts = [sp_model.encode(text, out_type=int) for text in texts]\n",
    "    max_len = max(len(x) for x in tokenized_texts)\n",
    "    padded_texts = [x + [0] * (max_len - len(x)) for x in tokenized_texts]  # Padding with 0\n",
    "    return padded_texts, max_len, sp_model.get_piece_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, max_len, vocab_size = tokenize_input(training_data['X'].tolist(), sp)\n",
    "pos_labels = training_data['pos'].tolist()\n",
    "contlex_labels = training_data['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_manager = LabelEncoderManager()\n",
    "\n",
    "encoder_manager.fit(pos_labels, contlex_labels)\n",
    "\n",
    "encoded_pos = encoder_manager.transform_pos(pos_labels)\n",
    "encoded_contlex = encoder_manager.transform_contlex(pos_labels, contlex_labels)\n",
    "\n",
    "# encoder_manager.save_encoders('label_encoders_3.pkl')\n",
    "\n",
    "encoder_manager.load_encoders('label_encoders_3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 52, 1: 21}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contlex_output_map = training_data.groupby(\"pos\")[\"label\"].nunique().to_dict()\n",
    "contlex_output_map = {encoder_manager.transform_pos([k])[0]: v for k, v in contlex_output_map.items()}\n",
    "contlex_output_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, pos_train, pos_val, contlex_train, contlex_val = train_test_split(X, encoded_pos, encoded_contlex, test_size=0.2, random_state=42, stratify=contlex_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(X_train, pos_train, contlex_train)\n",
    "val_dataset = CustomDataset(X_val, pos_val, contlex_val)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedEmbeddingTransformer(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pos_num_classes,\n",
    "        contlex_output_map,\n",
    "        vocab_size,\n",
    "        embed_size=96,\n",
    "        hidden_size=128,\n",
    "        num_layers=2,\n",
    "        nhead=4,\n",
    "        dropout=0.1,\n",
    "        learning_rate=1e-3,\n",
    "        batch_size=32,\n",
    "    ):\n",
    "        super(SharedEmbeddingTransformer, self).__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=vocab_size, embedding_dim=embed_size, padding_idx=0\n",
    "        )\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_size,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=hidden_size,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.fc_out_pos = nn.Linear(embed_size, pos_num_classes)\n",
    "\n",
    "        self.fc_out_contlex = nn.ModuleDict(\n",
    "            {\n",
    "                str(pos_class): nn.Linear(embed_size, contlex_output_map[pos_class])\n",
    "                for pos_class in contlex_output_map\n",
    "            }\n",
    "        )\n",
    "\n",
    "        nn.init.xavier_uniform_(self.embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.fc_out_pos.weight)\n",
    "\n",
    "        for pos_class in contlex_output_map:\n",
    "            nn.init.xavier_uniform_(self.fc_out_contlex[str(pos_class)].weight)\n",
    "\n",
    "        self.pos_weight = 1.0\n",
    "        self.contlex_weight = 1.0\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.contlex_output_map = contlex_output_map\n",
    "        self.pos_class_sorted = list(sorted(contlex_output_map.keys()))\n",
    "        self.contlex_class_max = max(contlex_output_map.values())\n",
    "\n",
    "        self.pos_f1 = MulticlassF1Score(num_classes=pos_num_classes, average=\"weighted\")\n",
    "        self.contlex_f1 = MulticlassF1Score(num_classes=self.contlex_class_max, average=\"weighted\")\n",
    "\n",
    "    def forward(self, x, pos_target=None):\n",
    "        x = self.embedding(x)\n",
    "        transformer_out = self.transformer_encoder(x)\n",
    "\n",
    "        transformer_last_hidden = transformer_out[:, -1, :]\n",
    "\n",
    "        pos_output = self.fc_out_pos(transformer_last_hidden)\n",
    "\n",
    "        pos_labels = pos_target if pos_target is not None else torch.argmax(pos_output, dim=1) \n",
    "\n",
    "        contlex_output = torch.zeros((x.size(0), self.contlex_class_max), device=self.device)\n",
    "\n",
    "        for pos_class in self.pos_class_sorted:\n",
    "            contlex_size = self.hparams.contlex_output_map[pos_class]\n",
    "            indices = (pos_labels == int(pos_class)).nonzero(as_tuple=True)[0]\n",
    "\n",
    "            if len(indices) > 0:\n",
    "                fc_out_contlex = self.fc_out_contlex[str(pos_class)]\n",
    "                contlex_out = fc_out_contlex(transformer_last_hidden[indices])\n",
    "                contlex_output[indices, :contlex_size] = contlex_out\n",
    "\n",
    "        return pos_output, contlex_output\n",
    "\n",
    "    def custom_loss(self, pos_output, contlex_output, pos_target, contlex_target):\n",
    "        pos_loss = nn.CrossEntropyLoss()(pos_output, pos_target)\n",
    "\n",
    "        contlex_loss = nn.CrossEntropyLoss()(contlex_output, contlex_target)\n",
    "\n",
    "        total_loss = self.pos_weight * pos_loss + self.contlex_weight * contlex_loss\n",
    "        return total_loss, pos_loss, contlex_loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, pos_y, contlex_y = batch\n",
    "        pos_output, contlex_output = self(x, pos_target=pos_y)\n",
    "\n",
    "        total_loss, pos_loss, contlex_loss = self.custom_loss(pos_output, contlex_output, pos_y, contlex_y)\n",
    "        self.log(\"train_loss\", total_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_pos_loss\", pos_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_contlex_loss\", contlex_loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, pos_y, contlex_y = batch\n",
    "        pos_output, contlex_output = self(x, pos_target=pos_y)\n",
    "\n",
    "        total_loss, pos_loss, contlex_loss = self.custom_loss(pos_output, contlex_output, pos_y, contlex_y)\n",
    "        self.log(\"val_loss\", total_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_pos_loss\", pos_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_contlex_loss\", contlex_loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        pos_preds = torch.argmax(pos_output, dim=1)\n",
    "        pos_acc = (pos_preds == pos_y).float().mean()\n",
    "        self.log(\"val_pos_acc\", pos_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        contlex_preds = torch.argmax(contlex_output, dim=1)                \n",
    "        contlex_acc = (contlex_preds == contlex_y).float().mean()\n",
    "        self.log(f\"val_contlex_acc\", contlex_acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        self.pos_f1(pos_preds, pos_y)\n",
    "        self.log(\"val_pos_f1\", self.pos_f1, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        self.contlex_f1(contlex_preds, contlex_y)\n",
    "        self.log(\"val_contlex_f1\", self.contlex_f1, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        self.log(\"lr\", self.trainer.optimizers[0].param_groups[0]['lr'], on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.95, patience=10)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=25)\n",
    "        # scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler, \"monitor\": \"val_loss\"}\n",
    "        \n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(val_dataset, batch_size=self.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embed_size = 128\n",
    "hidden_size = 512\n",
    "num_layers = 3\n",
    "nhead = 8\n",
    "dropout = 0.2\n",
    "epochs = 100\n",
    "learning_rate = 0.003\n",
    "batch_size = 512\n",
    "\n",
    "pos_num_classes = len(set(pos_labels))\n",
    "\n",
    "date_time_str = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "model = SharedEmbeddingTransformer(\n",
    "    pos_num_classes, \n",
    "    contlex_output_map, \n",
    "    vocab_size, \n",
    "    embed_size=embed_size,\n",
    "    hidden_size=hidden_size, \n",
    "    num_layers=num_layers,\n",
    "    nhead=nhead,\n",
    "    dropout=dropout,\n",
    "    learning_rate=learning_rate,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "print(model.hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "     monitor='val_loss',\n",
    "     dirpath=f\"./model/{date_time_str}/\",\n",
    "     filename='model-{epoch:02d}-{val_loss:.2f}-{val_contlex_f1:.2f}',\n",
    "     mode=\"min\",\n",
    "     enable_version_counter=True,\n",
    "    #  save_last=True,\n",
    ")\n",
    "\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=10, verbose=False, mode=\"min\")\n",
    "\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    min_epochs=100,\n",
    "    max_epochs=epochs,\n",
    "    accumulate_grad_batches=4,\n",
    "    callbacks=[\n",
    "        # early_stop_callback, \n",
    "        StochasticWeightAveraging(swa_lrs=1e-2), checkpoint_callback]\n",
    ")\n",
    "\n",
    "# tuner = Tuner(trainer)\n",
    "# tuner.scale_batch_size(model, mode=\"power\")\n",
    "# lr_finder = tuner.lr_find(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = lr_finder.plot(suggest=True)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TO TRAIN, uncomment\n",
    "# trainer.fit(model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= SharedEmbeddingTransformer.load_from_checkpoint(f\"./model/BEST/final_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexeme</th>\n",
       "      <th>language</th>\n",
       "      <th>pos</th>\n",
       "      <th>stem_text</th>\n",
       "      <th>contlex</th>\n",
       "      <th>forms</th>\n",
       "      <th>label</th>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12779</th>\n",
       "      <td>nõmmpeiʹvv</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>nõmm#pẹ%^1VOWi%{ʹØ%}vv</td>\n",
       "      <td>N_PEIQVV</td>\n",
       "      <td>nõmmpeeiʹvest nõmmpeivva nõmmpeeiʹvi nõmmpeiʹv...</td>\n",
       "      <td>N_PEIQVV</td>\n",
       "      <td>nõmmpeiʹvv nõmmpeeiʹvest nõmmpeivva nõmmpeeiʹv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4633</th>\n",
       "      <td>mååustpeʹrrjummuš</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>mååustpeʹrr»jummuš</td>\n",
       "      <td>N_MAINSTUMMUSH</td>\n",
       "      <td>mååustpeʹrrjummšest mååustpeʹrrjummša mååustpe...</td>\n",
       "      <td>N_MAINSTUMMUSH</td>\n",
       "      <td>mååustpeʹrrjummuš mååustpeʹrrjummšest mååustpe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13527</th>\n",
       "      <td>vuetǩǩummuš</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>vuetǩǩummuš</td>\n",
       "      <td>N_MAINSTUMMUSH</td>\n",
       "      <td>vuetǩǩummšest vuetǩǩummša vuetǩǩummši vuetǩǩum...</td>\n",
       "      <td>N_MAINSTUMMUSH</td>\n",
       "      <td>vuetǩǩummuš vuetǩǩummšest vuetǩǩummša vuetǩǩum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16047</th>\n",
       "      <td>säähharpõõst</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>säähhar#põ%^1VOW%{ʹØ%}stt</td>\n",
       "      <td>N_ALGG_PL</td>\n",
       "      <td>säähharpõõsti säähharpõsttân</td>\n",
       "      <td>N_ALGG</td>\n",
       "      <td>säähharpõõst säähharpõõsti säähharpõsttân</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>čåuʹjjmoiʹvvjummuš</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>čåuʹjjmoiʹvv»jummuš</td>\n",
       "      <td>N_MAINSTUMMUSH</td>\n",
       "      <td>čåuʹjjmoiʹvvjummšest čåuʹjjmoiʹvvjummša čåuʹjj...</td>\n",
       "      <td>N_MAINSTUMMUSH</td>\n",
       "      <td>čåuʹjjmoiʹvvjummuš čåuʹjjmoiʹvvjummšest čåuʹjj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17588</th>\n",
       "      <td>ämmat-tuʹtǩǩõs</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>ämmat#tuʹtǩǩõ%^1VOW%{ʹØ%}s</td>\n",
       "      <td>N_SAJOS</td>\n",
       "      <td>ämmat-tuʹtǩǩõõzzâst ämmat-tuʹtǩǩõʹsse ämmat-tu...</td>\n",
       "      <td>N_SAJOS</td>\n",
       "      <td>ämmat-tuʹtǩǩõs ämmat-tuʹtǩǩõõzzâst ämmat-tuʹtǩ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12648</th>\n",
       "      <td>njiõkknjâʹstted</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>njiõkknjâ%^1VOW%{ʹØ%}stt</td>\n",
       "      <td>V_CEQPCCED</td>\n",
       "      <td>njiõkknjââʹst njiõkknjâstt njiõkknjõʹsttem nji...</td>\n",
       "      <td>V_CEQPCCED</td>\n",
       "      <td>njiõkknjâʹstted njiõkknjââʹst njiõkknjâstt nji...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15104</th>\n",
       "      <td>rieʹǧǧtummuš</td>\n",
       "      <td>sms</td>\n",
       "      <td>N</td>\n",
       "      <td>rieʹǧǧtummuš</td>\n",
       "      <td>N_MAINSTUMMUSH</td>\n",
       "      <td>rieʹǧǧtummšest rieʹǧǧtummša rieʹǧǧtummši rieʹǧ...</td>\n",
       "      <td>N_MAINSTUMMUSH</td>\n",
       "      <td>rieʹǧǧtummuš rieʹǧǧtummšest rieʹǧǧtummša rieʹǧ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>kuärččjed</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>kuärčč</td>\n",
       "      <td>V_KUYDHDHDHJED</td>\n",
       "      <td>kuårčču kuärččai kuärččjem kuärččji kuärččjed ...</td>\n",
       "      <td>V_KUYDHDHDHJED</td>\n",
       "      <td>kuärččjed kuårčču kuärččai kuärččjem kuärččji ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15417</th>\n",
       "      <td>škuärted</td>\n",
       "      <td>sms</td>\n",
       "      <td>V</td>\n",
       "      <td>škuärat</td>\n",
       "      <td>V_SHORRNED</td>\n",
       "      <td>škuärat škuärat škuärtem škuärti škuärted škuä...</td>\n",
       "      <td>V_SHORRNED</td>\n",
       "      <td>škuärted škuärat škuärat škuärtem škuärti škuä...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1858 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   lexeme language pos                   stem_text  \\\n",
       "12779          nõmmpeiʹvv      sms   N      nõmm#pẹ%^1VOWi%{ʹØ%}vv   \n",
       "4633    mååustpeʹrrjummuš      sms   N          mååustpeʹrr»jummuš   \n",
       "13527         vuetǩǩummuš      sms   N                 vuetǩǩummuš   \n",
       "16047        säähharpõõst      sms   N   säähhar#põ%^1VOW%{ʹØ%}stt   \n",
       "3795   čåuʹjjmoiʹvvjummuš      sms   N         čåuʹjjmoiʹvv»jummuš   \n",
       "...                   ...      ...  ..                         ...   \n",
       "17588      ämmat-tuʹtǩǩõs      sms   N  ämmat#tuʹtǩǩõ%^1VOW%{ʹØ%}s   \n",
       "12648     njiõkknjâʹstted      sms   V    njiõkknjâ%^1VOW%{ʹØ%}stt   \n",
       "15104        rieʹǧǧtummuš      sms   N                rieʹǧǧtummuš   \n",
       "102             kuärččjed      sms   V                      kuärčč   \n",
       "15417            škuärted      sms   V                     škuärat   \n",
       "\n",
       "              contlex                                              forms  \\\n",
       "12779        N_PEIQVV  nõmmpeeiʹvest nõmmpeivva nõmmpeeiʹvi nõmmpeiʹv...   \n",
       "4633   N_MAINSTUMMUSH  mååustpeʹrrjummšest mååustpeʹrrjummša mååustpe...   \n",
       "13527  N_MAINSTUMMUSH  vuetǩǩummšest vuetǩǩummša vuetǩǩummši vuetǩǩum...   \n",
       "16047       N_ALGG_PL                       säähharpõõsti säähharpõsttân   \n",
       "3795   N_MAINSTUMMUSH  čåuʹjjmoiʹvvjummšest čåuʹjjmoiʹvvjummša čåuʹjj...   \n",
       "...               ...                                                ...   \n",
       "17588         N_SAJOS  ämmat-tuʹtǩǩõõzzâst ämmat-tuʹtǩǩõʹsse ämmat-tu...   \n",
       "12648      V_CEQPCCED  njiõkknjââʹst njiõkknjâstt njiõkknjõʹsttem nji...   \n",
       "15104  N_MAINSTUMMUSH  rieʹǧǧtummšest rieʹǧǧtummša rieʹǧǧtummši rieʹǧ...   \n",
       "102    V_KUYDHDHDHJED  kuårčču kuärččai kuärččjem kuärččji kuärččjed ...   \n",
       "15417      V_SHORRNED  škuärat škuärat škuärtem škuärti škuärted škuä...   \n",
       "\n",
       "                label                                                  X  \n",
       "12779        N_PEIQVV  nõmmpeiʹvv nõmmpeeiʹvest nõmmpeivva nõmmpeeiʹv...  \n",
       "4633   N_MAINSTUMMUSH  mååustpeʹrrjummuš mååustpeʹrrjummšest mååustpe...  \n",
       "13527  N_MAINSTUMMUSH  vuetǩǩummuš vuetǩǩummšest vuetǩǩummša vuetǩǩum...  \n",
       "16047          N_ALGG          säähharpõõst säähharpõõsti säähharpõsttân  \n",
       "3795   N_MAINSTUMMUSH  čåuʹjjmoiʹvvjummuš čåuʹjjmoiʹvvjummšest čåuʹjj...  \n",
       "...               ...                                                ...  \n",
       "17588         N_SAJOS  ämmat-tuʹtǩǩõs ämmat-tuʹtǩǩõõzzâst ämmat-tuʹtǩ...  \n",
       "12648      V_CEQPCCED  njiõkknjâʹstted njiõkknjââʹst njiõkknjâstt nji...  \n",
       "15104  N_MAINSTUMMUSH  rieʹǧǧtummuš rieʹǧǧtummšest rieʹǧǧtummša rieʹǧ...  \n",
       "102    V_KUYDHDHDHJED  kuärččjed kuårčču kuärččai kuärččjem kuärččji ...  \n",
       "15417      V_SHORRNED  škuärted škuärat škuärat škuärtem škuärti škuä...  \n",
       "\n",
       "[1858 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"batch_size\":         512\n",
      "\"contlex_output_map\": {0: 52, 1: 21}\n",
      "\"dropout\":            0.2\n",
      "\"embed_size\":         128\n",
      "\"hidden_size\":        512\n",
      "\"learning_rate\":      0.003\n",
      "\"nhead\":              8\n",
      "\"num_layers\":         3\n",
      "\"pos_num_classes\":    2\n",
      "\"vocab_size\":         2000\n"
     ]
    }
   ],
   "source": [
    "print(model.hparams)\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       1.00      1.00      1.00      1520\n",
      "           V       1.00      1.00      1.00       338\n",
      "\n",
      "    accuracy                           1.00      1858\n",
      "   macro avg       1.00      1.00      1.00      1858\n",
      "weighted avg       1.00      1.00      1.00      1858\n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "IV_LAUKKOOLLYD       0.69      0.88      0.77        33\n",
      "     N_AACCIKH       1.00      1.00      1.00        18\n",
      "       N_AANAR       0.98      0.95      0.97        62\n",
      "       N_AELDD       0.70      0.88      0.78        24\n",
      "        N_ALGG       0.88      0.90      0.89        51\n",
      "        N_ATOM       0.25      0.17      0.20         6\n",
      "        N_AUTT       0.61      0.85      0.71        13\n",
      "    N_BIOLOGIA       0.94      1.00      0.97        15\n",
      "     N_CHAAQCC       0.94      1.00      0.97        16\n",
      "    N_CHUAQRVV       1.00      0.71      0.83         7\n",
      "    N_CHUOSHKK       0.83      0.71      0.77         7\n",
      "      N_HOQPPI       0.83      0.83      0.83         6\n",
      "     N_JAEUQRR       0.89      0.89      0.89         9\n",
      "     N_JEAQNNN       0.85      0.85      0.85        13\n",
      "     N_JEAQRMM       0.91      1.00      0.95        10\n",
      "      N_JUQVJJ       1.00      1.00      1.00        15\n",
      "       N_JUURD       1.00      1.00      1.00         5\n",
      "   N_KAADHNEKH       1.00      1.00      1.00        15\n",
      "      N_KAQLBB       0.89      0.86      0.88        29\n",
      "     N_KHEQRJJ       1.00      1.00      1.00         5\n",
      "     N_KUEAQTT       1.00      0.50      0.67         6\n",
      "      N_KUEQLL       0.71      0.83      0.77         6\n",
      "     N_KUYLAZH       0.95      1.00      0.97        18\n",
      "      N_LOAQDD       0.91      0.97      0.94        33\n",
      "N_MAINSTUMMUSH       0.33      0.32      0.33       156\n",
      "    N_MEERSAZH       1.00      1.00      1.00        18\n",
      "     N_MIEAQRR       0.90      1.00      0.95         9\n",
      "      N_MIYRKK       0.86      0.75      0.80         8\n",
      "     N_MUEQRJJ       0.71      0.62      0.67         8\n",
      "       N_MUORR       1.00      0.99      0.99        79\n",
      "     N_MUORYZH       1.00      1.00      1.00         6\n",
      "      N_NEAVVV       1.00      0.71      0.83         7\n",
      "     N_OOUMAZH       1.00      1.00      1.00         9\n",
      "      N_PAAQJJ       1.00      1.00      1.00        10\n",
      "       N_PAARR       0.67      0.67      0.67         6\n",
      "    N_PAIQKHKH       0.95      0.95      0.95        21\n",
      "        N_PAPP       0.89      0.89      0.89        36\n",
      "     N_PEAELDD       1.00      0.50      0.67         6\n",
      "      N_PEIQVV       1.00      1.00      1.00        11\n",
      "        N_PESS       0.95      0.95      0.95        21\n",
      "     N_PIEAQSS       1.00      0.83      0.91         6\n",
      "       N_PLAAN       0.70      0.73      0.71        22\n",
      "      N_SAAQMM       1.00      0.88      0.94        17\n",
      "       N_SAJOS       0.82      0.83      0.82       597\n",
      "      N_SHOOMM       0.80      0.89      0.84         9\n",
      "       N_SIJDD       1.00      1.00      1.00         5\n",
      "      N_SIYKKK       1.00      0.80      0.89         5\n",
      "     N_TAALKYS       0.69      0.90      0.78        10\n",
      "      N_TAQHTT       1.00      0.80      0.89         5\n",
      "        N_TOLL       0.80      0.84      0.82        19\n",
      "       N_TUYJJ       0.88      1.00      0.93         7\n",
      "      N_VOONYS       0.75      0.43      0.55         7\n",
      "       N_VUYRR       1.00      0.82      0.90        11\n",
      "   TV_VOQLLJED       0.30      0.38      0.33         8\n",
      "    V_AALGXTED       0.67      0.86      0.75        14\n",
      "    V_CEQPCCED       1.00      0.95      0.97        20\n",
      "   V_JEAELSTED       0.50      0.20      0.29         5\n",
      "    V_KAEQTTED       1.00      0.94      0.97        16\n",
      "  V_KHEEQRJTED       0.85      0.73      0.79        15\n",
      "  V_KHIORGGNED       0.56      0.60      0.58        15\n",
      "V_KUYDHDHDHJED       1.00      0.91      0.95        11\n",
      " V_LAUKKOOLLYD       0.91      0.80      0.85        61\n",
      "     V_POOLLYD       0.86      0.86      0.86         7\n",
      "      V_ROVVYD       0.80      0.80      0.80         5\n",
      "     V_SARNNAD       1.00      1.00      1.00         6\n",
      " V_SHKUEAQTTED       0.95      1.00      0.97        19\n",
      "    V_SHORRNED       0.71      0.68      0.69        25\n",
      "    V_SILTTEED       0.95      0.86      0.90        22\n",
      "     V_SOLLEED       0.86      0.86      0.86        14\n",
      "    V_TEEQMEED       0.82      0.95      0.88        19\n",
      "     V_TOBDDYD       0.86      1.00      0.92         6\n",
      "     V_VIIKKYD       1.00      1.00      1.00         6\n",
      "    V_VOQLLJED       0.38      0.27      0.32        11\n",
      "\n",
      "      accuracy                           0.81      1858\n",
      "     macro avg       0.86      0.83      0.84      1858\n",
      "  weighted avg       0.81      0.81      0.81      1858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, row in test_data.iterrows():\n",
    "    x_tokenized = sp.encode(row[\"X\"], out_type=int)\n",
    "    x = torch.tensor([x_tokenized], dtype=torch.long).to(device)\n",
    "    pos_output, _ = model(x)\n",
    "    pos_pred = torch.argmax(pos_output, dim=1)\n",
    "\n",
    "    pos_target_main = encoder_manager.transform_pos([row[\"pos\"]])\n",
    "    pos_target = torch.tensor(pos_target_main, dtype=torch.long).to(device)\n",
    "\n",
    "    _, contlex_output = model(x, pos_target=pos_target)\n",
    "    contlex_pred = torch.argmax(contlex_output, dim=1)\n",
    "    pos_label = encoder_manager.inverse_transform_pos([pos_pred.item()])[0]\n",
    "    contlex_label = encoder_manager.inverse_transform_contlex([row[\"pos\"]], [contlex_pred.item()])[0]\n",
    "    test_data.at[i, f\"pos_pred\"] = pos_label\n",
    "    test_data.at[i, f\"contlex_pred\"] = contlex_label\n",
    "\n",
    "print(classification_report(test_data[\"pos\"], test_data[f\"pos_pred\"]))\n",
    "print(classification_report(test_data[\"label\"], test_data[f\"contlex_pred\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len_of_X_words = test_data[\"X\"].apply(lambda x: x.count(\" \")).max()\n",
    "max_len_of_X_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of words: 1\n",
      "POS Accuracy: 0.9736275565123789\n",
      "Contlex Accuracy: 0.36544671689989233\n",
      "\n",
      "Max number of words: 2\n",
      "POS Accuracy: 0.9757804090419806\n",
      "Contlex Accuracy: 0.569967707212056\n",
      "\n",
      "Max number of words: 3\n",
      "POS Accuracy: 0.9644779332615716\n",
      "Contlex Accuracy: 0.6178686759956943\n",
      "\n",
      "Max number of words: 4\n",
      "POS Accuracy: 0.9720129171151776\n",
      "Contlex Accuracy: 0.6792249730893434\n",
      "\n",
      "Max number of words: 5\n",
      "POS Accuracy: 0.9741657696447793\n",
      "Contlex Accuracy: 0.689989235737352\n",
      "\n",
      "Max number of words: 6\n",
      "POS Accuracy: 0.9752421959095802\n",
      "Contlex Accuracy: 0.6926803013993541\n",
      "\n",
      "Max number of words: 7\n",
      "POS Accuracy: 0.9790096878363832\n",
      "Contlex Accuracy: 0.7072120559741658\n",
      "\n",
      "Max number of words: 8\n",
      "POS Accuracy: 0.988697524219591\n",
      "Contlex Accuracy: 0.7561894510226049\n",
      "\n",
      "Max number of words: 9\n",
      "POS Accuracy: 0.9827771797631862\n",
      "Contlex Accuracy: 0.7734122712594187\n",
      "\n",
      "Max number of words: 10\n",
      "POS Accuracy: 0.9860064585575888\n",
      "Contlex Accuracy: 0.778794402583423\n",
      "\n",
      "Max number of words: 11\n",
      "POS Accuracy: 0.9881593110871906\n",
      "Contlex Accuracy: 0.7927879440258342\n",
      "\n",
      "Max number of words: 12\n",
      "POS Accuracy: 0.996232508073197\n",
      "Contlex Accuracy: 0.8078579117330463\n",
      "\n",
      "Max number of words: 13\n",
      "POS Accuracy: 0.9989235737351991\n",
      "Contlex Accuracy: 0.8073196986006459\n",
      "\n",
      "Max number of words: 14\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8121636167922497\n",
      "\n",
      "Max number of words: 15\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8116254036598493\n",
      "\n",
      "Max number of words: 16\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8116254036598493\n",
      "\n",
      "Max number of words: 17\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8121636167922497\n",
      "\n",
      "Max number of words: 18\n",
      "POS Accuracy: 0.9989235737351991\n",
      "Contlex Accuracy: 0.8121636167922497\n",
      "\n",
      "Max number of words: 19\n",
      "POS Accuracy: 0.9989235737351991\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 20\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8121636167922497\n",
      "\n",
      "Max number of words: 21\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8132400430570506\n",
      "\n",
      "Max number of words: 22\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8132400430570506\n",
      "\n",
      "Max number of words: 23\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8132400430570506\n",
      "\n",
      "Max number of words: 24\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 25\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 26\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 27\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 28\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 29\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 30\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 31\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 32\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 33\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 34\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 35\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 36\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 37\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 38\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 39\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8121636167922497\n",
      "\n",
      "Max number of words: 40\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 41\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8121636167922497\n",
      "\n",
      "Max number of words: 42\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 43\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 44\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 45\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 46\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 47\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 48\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 49\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 50\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 51\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n",
      "Max number of words: 52\n",
      "POS Accuracy: 0.9994617868675996\n",
      "Contlex Accuracy: 0.8127018299246501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for j in range(1, max_len_of_X_words + 1):\n",
    "    print(f\"Max number of words: {j}\")\n",
    "\n",
    "    for i, row in test_data.iterrows():\n",
    "        X_with_max_j_words = \" \".join(row[\"X\"].split()[:j])\n",
    "        x_tokenized = sp.encode(X_with_max_j_words, out_type=int)\n",
    "        x = torch.tensor([x_tokenized], dtype=torch.long).to(device)\n",
    "        pos_output, _ = model(x)\n",
    "        pos_pred = torch.argmax(pos_output, dim=1)\n",
    "\n",
    "        pos_target_main = encoder_manager.transform_pos([row[\"pos\"]])\n",
    "        pos_target = torch.tensor(pos_target_main, dtype=torch.long).to(device)\n",
    "\n",
    "        _, contlex_output = model(x, pos_target=pos_target)\n",
    "        contlex_pred = torch.argmax(contlex_output, dim=1)\n",
    "        pos_label = encoder_manager.inverse_transform_pos([pos_pred.item()])[0]\n",
    "        contlex_label = encoder_manager.inverse_transform_contlex([row[\"pos\"]], [contlex_pred.item()])[0]\n",
    "        test_data.at[i, f\"pos_pred\"] = pos_label\n",
    "        test_data.at[i, f\"contlex_pred\"] = contlex_label\n",
    "\n",
    "    print(\"POS Accuracy:\", accuracy_score(test_data[\"pos\"], test_data[f\"pos_pred\"]))\n",
    "    print(\"Contlex Accuracy:\", accuracy_score(test_data[\"label\"], test_data[f\"contlex_pred\"]))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
